<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><meta name="description" content="Brent&#x27;s homepage"/><meta name="author" content="Brent Tan"/><title>Brent Tan - Homepage</title><meta name="next-head-count" content="5"/><link data-next-font="" rel="preconnect" href="/" crossorigin="anonymous"/><link rel="preload" href="/_next/static/css/e9556718e3f0f4cf.css" as="style"/><link rel="stylesheet" href="/_next/static/css/e9556718e3f0f4cf.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-c7e8ec73d08c57f3.js" defer=""></script><script src="/_next/static/chunks/framework-64ad27b21261a9ce.js" defer=""></script><script src="/_next/static/chunks/main-676fc21436baeb6f.js" defer=""></script><script src="/_next/static/chunks/pages/_app-cb76b27212f05dea.js" defer=""></script><script src="/_next/static/chunks/175675d1-254dc21e030ba2ac.js" defer=""></script><script src="/_next/static/chunks/645-40e6d947d4f7bb86.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-9dc0ab71c3bdc569.js" defer=""></script><script src="/_next/static/FUrf4hjRe_AMnPlFUzSZF/_buildManifest.js" defer=""></script><script src="/_next/static/FUrf4hjRe_AMnPlFUzSZF/_ssgManifest.js" defer=""></script><style id="__jsx-fed65fd97a038da">@import url("https://fonts.googleapis.com/css2?family=M+PLUS+Rounded+1c:wght@300;700&display=swap");@import url("https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@100..900&display=swap");</style></head><body><script id="chakra-script">!(function(){try{var a=function(c){var v="(prefers-color-scheme: dark)",h=window.matchMedia(v).matches?"dark":"light",r=c==="system"?h:c,o=document.documentElement,s=document.body,l="chakra-ui-light",d="chakra-ui-dark",i=r==="dark";return s.classList.add(i?d:l),s.classList.remove(i?l:d),o.style.colorScheme=r,o.dataset.theme=r,r},n=a,m="dark",e="chakra-ui-color-mode",t=localStorage.getItem(e);t?a(t):localStorage.setItem(e,a(m))}catch(a){}})();</script><div id="__next"><style data-emotion="css-global 93m1n8">:host,:root,[data-theme]{--chakra-ring-inset:var(--chakra-empty,/*!*/ /*!*/);--chakra-ring-offset-width:0px;--chakra-ring-offset-color:#fff;--chakra-ring-color:rgba(66, 153, 225, 0.6);--chakra-ring-offset-shadow:0 0 #0000;--chakra-ring-shadow:0 0 #0000;--chakra-space-x-reverse:0;--chakra-space-y-reverse:0;--chakra-colors-transparent:transparent;--chakra-colors-current:currentColor;--chakra-colors-black:#000000;--chakra-colors-white:#FFFFFF;--chakra-colors-whiteAlpha-50:rgba(255, 255, 255, 0.04);--chakra-colors-whiteAlpha-100:rgba(255, 255, 255, 0.06);--chakra-colors-whiteAlpha-200:rgba(255, 255, 255, 0.08);--chakra-colors-whiteAlpha-300:rgba(255, 255, 255, 0.16);--chakra-colors-whiteAlpha-400:rgba(255, 255, 255, 0.24);--chakra-colors-whiteAlpha-500:rgba(255, 255, 255, 0.36);--chakra-colors-whiteAlpha-600:rgba(255, 255, 255, 0.48);--chakra-colors-whiteAlpha-700:rgba(255, 255, 255, 0.64);--chakra-colors-whiteAlpha-800:rgba(255, 255, 255, 0.80);--chakra-colors-whiteAlpha-900:rgba(255, 255, 255, 0.92);--chakra-colors-blackAlpha-50:rgba(0, 0, 0, 0.04);--chakra-colors-blackAlpha-100:rgba(0, 0, 0, 0.06);--chakra-colors-blackAlpha-200:rgba(0, 0, 0, 0.08);--chakra-colors-blackAlpha-300:rgba(0, 0, 0, 0.16);--chakra-colors-blackAlpha-400:rgba(0, 0, 0, 0.24);--chakra-colors-blackAlpha-500:rgba(0, 0, 0, 0.36);--chakra-colors-blackAlpha-600:rgba(0, 0, 0, 0.48);--chakra-colors-blackAlpha-700:rgba(0, 0, 0, 0.64);--chakra-colors-blackAlpha-800:rgba(0, 0, 0, 0.80);--chakra-colors-blackAlpha-900:rgba(0, 0, 0, 0.92);--chakra-colors-gray-50:#F7FAFC;--chakra-colors-gray-100:#EDF2F7;--chakra-colors-gray-200:#E2E8F0;--chakra-colors-gray-300:#CBD5E0;--chakra-colors-gray-400:#A0AEC0;--chakra-colors-gray-500:#718096;--chakra-colors-gray-600:#4A5568;--chakra-colors-gray-700:#2D3748;--chakra-colors-gray-800:#1A202C;--chakra-colors-gray-900:#171923;--chakra-colors-red-50:#FFF5F5;--chakra-colors-red-100:#FED7D7;--chakra-colors-red-200:#FEB2B2;--chakra-colors-red-300:#FC8181;--chakra-colors-red-400:#F56565;--chakra-colors-red-500:#E53E3E;--chakra-colors-red-600:#C53030;--chakra-colors-red-700:#9B2C2C;--chakra-colors-red-800:#822727;--chakra-colors-red-900:#63171B;--chakra-colors-orange-50:#FFFAF0;--chakra-colors-orange-100:#FEEBC8;--chakra-colors-orange-200:#FBD38D;--chakra-colors-orange-300:#F6AD55;--chakra-colors-orange-400:#ED8936;--chakra-colors-orange-500:#DD6B20;--chakra-colors-orange-600:#C05621;--chakra-colors-orange-700:#9C4221;--chakra-colors-orange-800:#7B341E;--chakra-colors-orange-900:#652B19;--chakra-colors-yellow-50:#FFFFF0;--chakra-colors-yellow-100:#FEFCBF;--chakra-colors-yellow-200:#FAF089;--chakra-colors-yellow-300:#F6E05E;--chakra-colors-yellow-400:#ECC94B;--chakra-colors-yellow-500:#D69E2E;--chakra-colors-yellow-600:#B7791F;--chakra-colors-yellow-700:#975A16;--chakra-colors-yellow-800:#744210;--chakra-colors-yellow-900:#5F370E;--chakra-colors-green-50:#F0FFF4;--chakra-colors-green-100:#C6F6D5;--chakra-colors-green-200:#9AE6B4;--chakra-colors-green-300:#68D391;--chakra-colors-green-400:#48BB78;--chakra-colors-green-500:#38A169;--chakra-colors-green-600:#2F855A;--chakra-colors-green-700:#276749;--chakra-colors-green-800:#22543D;--chakra-colors-green-900:#1C4532;--chakra-colors-teal-50:#E6FFFA;--chakra-colors-teal-100:#B2F5EA;--chakra-colors-teal-200:#81E6D9;--chakra-colors-teal-300:#4FD1C5;--chakra-colors-teal-400:#38B2AC;--chakra-colors-teal-500:#319795;--chakra-colors-teal-600:#2C7A7B;--chakra-colors-teal-700:#285E61;--chakra-colors-teal-800:#234E52;--chakra-colors-teal-900:#1D4044;--chakra-colors-blue-50:#ebf8ff;--chakra-colors-blue-100:#bee3f8;--chakra-colors-blue-200:#90cdf4;--chakra-colors-blue-300:#63b3ed;--chakra-colors-blue-400:#4299e1;--chakra-colors-blue-500:#3182ce;--chakra-colors-blue-600:#2b6cb0;--chakra-colors-blue-700:#2c5282;--chakra-colors-blue-800:#2a4365;--chakra-colors-blue-900:#1A365D;--chakra-colors-cyan-50:#EDFDFD;--chakra-colors-cyan-100:#C4F1F9;--chakra-colors-cyan-200:#9DECF9;--chakra-colors-cyan-300:#76E4F7;--chakra-colors-cyan-400:#0BC5EA;--chakra-colors-cyan-500:#00B5D8;--chakra-colors-cyan-600:#00A3C4;--chakra-colors-cyan-700:#0987A0;--chakra-colors-cyan-800:#086F83;--chakra-colors-cyan-900:#065666;--chakra-colors-purple-50:#FAF5FF;--chakra-colors-purple-100:#E9D8FD;--chakra-colors-purple-200:#D6BCFA;--chakra-colors-purple-300:#B794F4;--chakra-colors-purple-400:#9F7AEA;--chakra-colors-purple-500:#805AD5;--chakra-colors-purple-600:#6B46C1;--chakra-colors-purple-700:#553C9A;--chakra-colors-purple-800:#44337A;--chakra-colors-purple-900:#322659;--chakra-colors-pink-50:#FFF5F7;--chakra-colors-pink-100:#FED7E2;--chakra-colors-pink-200:#FBB6CE;--chakra-colors-pink-300:#F687B3;--chakra-colors-pink-400:#ED64A6;--chakra-colors-pink-500:#D53F8C;--chakra-colors-pink-600:#B83280;--chakra-colors-pink-700:#97266D;--chakra-colors-pink-800:#702459;--chakra-colors-pink-900:#521B41;--chakra-colors-linkedin-50:#E8F4F9;--chakra-colors-linkedin-100:#CFEDFB;--chakra-colors-linkedin-200:#9BDAF3;--chakra-colors-linkedin-300:#68C7EC;--chakra-colors-linkedin-400:#34B3E4;--chakra-colors-linkedin-500:#00A0DC;--chakra-colors-linkedin-600:#008CC9;--chakra-colors-linkedin-700:#0077B5;--chakra-colors-linkedin-800:#005E93;--chakra-colors-linkedin-900:#004471;--chakra-colors-facebook-50:#E8F4F9;--chakra-colors-facebook-100:#D9DEE9;--chakra-colors-facebook-200:#B7C2DA;--chakra-colors-facebook-300:#6482C0;--chakra-colors-facebook-400:#4267B2;--chakra-colors-facebook-500:#385898;--chakra-colors-facebook-600:#314E89;--chakra-colors-facebook-700:#29487D;--chakra-colors-facebook-800:#223B67;--chakra-colors-facebook-900:#1E355B;--chakra-colors-messenger-50:#D0E6FF;--chakra-colors-messenger-100:#B9DAFF;--chakra-colors-messenger-200:#A2CDFF;--chakra-colors-messenger-300:#7AB8FF;--chakra-colors-messenger-400:#2E90FF;--chakra-colors-messenger-500:#0078FF;--chakra-colors-messenger-600:#0063D1;--chakra-colors-messenger-700:#0052AC;--chakra-colors-messenger-800:#003C7E;--chakra-colors-messenger-900:#002C5C;--chakra-colors-whatsapp-50:#dffeec;--chakra-colors-whatsapp-100:#b9f5d0;--chakra-colors-whatsapp-200:#90edb3;--chakra-colors-whatsapp-300:#65e495;--chakra-colors-whatsapp-400:#3cdd78;--chakra-colors-whatsapp-500:#22c35e;--chakra-colors-whatsapp-600:#179848;--chakra-colors-whatsapp-700:#0c6c33;--chakra-colors-whatsapp-800:#01421c;--chakra-colors-whatsapp-900:#001803;--chakra-colors-twitter-50:#E5F4FD;--chakra-colors-twitter-100:#C8E9FB;--chakra-colors-twitter-200:#A8DCFA;--chakra-colors-twitter-300:#83CDF7;--chakra-colors-twitter-400:#57BBF5;--chakra-colors-twitter-500:#1DA1F2;--chakra-colors-twitter-600:#1A94DA;--chakra-colors-twitter-700:#1681BF;--chakra-colors-twitter-800:#136B9E;--chakra-colors-twitter-900:#0D4D71;--chakra-colors-telegram-50:#E3F2F9;--chakra-colors-telegram-100:#C5E4F3;--chakra-colors-telegram-200:#A2D4EC;--chakra-colors-telegram-300:#7AC1E4;--chakra-colors-telegram-400:#47A9DA;--chakra-colors-telegram-500:#0088CC;--chakra-colors-telegram-600:#007AB8;--chakra-colors-telegram-700:#006BA1;--chakra-colors-telegram-800:#005885;--chakra-colors-telegram-900:#003F5E;--chakra-colors-grassTeal:#88ccca;--chakra-borders-none:0;--chakra-borders-1px:1px solid;--chakra-borders-2px:2px solid;--chakra-borders-4px:4px solid;--chakra-borders-8px:8px solid;--chakra-fonts-heading:'M PLUS Rounded 1c';--chakra-fonts-body:-apple-system,BlinkMacSystemFont,"Segoe UI",Helvetica,Arial,sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol";--chakra-fonts-mono:SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;--chakra-fontSizes-3xs:0.45rem;--chakra-fontSizes-2xs:0.625rem;--chakra-fontSizes-xs:0.75rem;--chakra-fontSizes-sm:0.875rem;--chakra-fontSizes-md:1rem;--chakra-fontSizes-lg:1.125rem;--chakra-fontSizes-xl:1.25rem;--chakra-fontSizes-2xl:1.5rem;--chakra-fontSizes-3xl:1.875rem;--chakra-fontSizes-4xl:2.25rem;--chakra-fontSizes-5xl:3rem;--chakra-fontSizes-6xl:3.75rem;--chakra-fontSizes-7xl:4.5rem;--chakra-fontSizes-8xl:6rem;--chakra-fontSizes-9xl:8rem;--chakra-fontWeights-hairline:100;--chakra-fontWeights-thin:200;--chakra-fontWeights-light:300;--chakra-fontWeights-normal:400;--chakra-fontWeights-medium:500;--chakra-fontWeights-semibold:600;--chakra-fontWeights-bold:700;--chakra-fontWeights-extrabold:800;--chakra-fontWeights-black:900;--chakra-letterSpacings-tighter:-0.05em;--chakra-letterSpacings-tight:-0.025em;--chakra-letterSpacings-normal:0;--chakra-letterSpacings-wide:0.025em;--chakra-letterSpacings-wider:0.05em;--chakra-letterSpacings-widest:0.1em;--chakra-lineHeights-3:.75rem;--chakra-lineHeights-4:1rem;--chakra-lineHeights-5:1.25rem;--chakra-lineHeights-6:1.5rem;--chakra-lineHeights-7:1.75rem;--chakra-lineHeights-8:2rem;--chakra-lineHeights-9:2.25rem;--chakra-lineHeights-10:2.5rem;--chakra-lineHeights-normal:normal;--chakra-lineHeights-none:1;--chakra-lineHeights-shorter:1.25;--chakra-lineHeights-short:1.375;--chakra-lineHeights-base:1.5;--chakra-lineHeights-tall:1.625;--chakra-lineHeights-taller:2;--chakra-radii-none:0;--chakra-radii-sm:0.125rem;--chakra-radii-base:0.25rem;--chakra-radii-md:0.375rem;--chakra-radii-lg:0.5rem;--chakra-radii-xl:0.75rem;--chakra-radii-2xl:1rem;--chakra-radii-3xl:1.5rem;--chakra-radii-full:9999px;--chakra-space-1:0.25rem;--chakra-space-2:0.5rem;--chakra-space-3:0.75rem;--chakra-space-4:1rem;--chakra-space-5:1.25rem;--chakra-space-6:1.5rem;--chakra-space-7:1.75rem;--chakra-space-8:2rem;--chakra-space-9:2.25rem;--chakra-space-10:2.5rem;--chakra-space-12:3rem;--chakra-space-14:3.5rem;--chakra-space-16:4rem;--chakra-space-20:5rem;--chakra-space-24:6rem;--chakra-space-28:7rem;--chakra-space-32:8rem;--chakra-space-36:9rem;--chakra-space-40:10rem;--chakra-space-44:11rem;--chakra-space-48:12rem;--chakra-space-52:13rem;--chakra-space-56:14rem;--chakra-space-60:15rem;--chakra-space-64:16rem;--chakra-space-72:18rem;--chakra-space-80:20rem;--chakra-space-96:24rem;--chakra-space-px:1px;--chakra-space-0-5:0.125rem;--chakra-space-1-5:0.375rem;--chakra-space-2-5:0.625rem;--chakra-space-3-5:0.875rem;--chakra-shadows-xs:0 0 0 1px rgba(0, 0, 0, 0.05);--chakra-shadows-sm:0 1px 2px 0 rgba(0, 0, 0, 0.05);--chakra-shadows-base:0 1px 3px 0 rgba(0, 0, 0, 0.1),0 1px 2px 0 rgba(0, 0, 0, 0.06);--chakra-shadows-md:0 4px 6px -1px rgba(0, 0, 0, 0.1),0 2px 4px -1px rgba(0, 0, 0, 0.06);--chakra-shadows-lg:0 10px 15px -3px rgba(0, 0, 0, 0.1),0 4px 6px -2px rgba(0, 0, 0, 0.05);--chakra-shadows-xl:0 20px 25px -5px rgba(0, 0, 0, 0.1),0 10px 10px -5px rgba(0, 0, 0, 0.04);--chakra-shadows-2xl:0 25px 50px -12px rgba(0, 0, 0, 0.25);--chakra-shadows-outline:0 0 0 3px rgba(66, 153, 225, 0.6);--chakra-shadows-inner:inset 0 2px 4px 0 rgba(0,0,0,0.06);--chakra-shadows-none:none;--chakra-shadows-dark-lg:rgba(0, 0, 0, 0.1) 0px 0px 0px 1px,rgba(0, 0, 0, 0.2) 0px 5px 10px,rgba(0, 0, 0, 0.4) 0px 15px 40px;--chakra-sizes-1:0.25rem;--chakra-sizes-2:0.5rem;--chakra-sizes-3:0.75rem;--chakra-sizes-4:1rem;--chakra-sizes-5:1.25rem;--chakra-sizes-6:1.5rem;--chakra-sizes-7:1.75rem;--chakra-sizes-8:2rem;--chakra-sizes-9:2.25rem;--chakra-sizes-10:2.5rem;--chakra-sizes-12:3rem;--chakra-sizes-14:3.5rem;--chakra-sizes-16:4rem;--chakra-sizes-20:5rem;--chakra-sizes-24:6rem;--chakra-sizes-28:7rem;--chakra-sizes-32:8rem;--chakra-sizes-36:9rem;--chakra-sizes-40:10rem;--chakra-sizes-44:11rem;--chakra-sizes-48:12rem;--chakra-sizes-52:13rem;--chakra-sizes-56:14rem;--chakra-sizes-60:15rem;--chakra-sizes-64:16rem;--chakra-sizes-72:18rem;--chakra-sizes-80:20rem;--chakra-sizes-96:24rem;--chakra-sizes-px:1px;--chakra-sizes-0-5:0.125rem;--chakra-sizes-1-5:0.375rem;--chakra-sizes-2-5:0.625rem;--chakra-sizes-3-5:0.875rem;--chakra-sizes-max:max-content;--chakra-sizes-min:min-content;--chakra-sizes-full:100%;--chakra-sizes-3xs:14rem;--chakra-sizes-2xs:16rem;--chakra-sizes-xs:20rem;--chakra-sizes-sm:24rem;--chakra-sizes-md:28rem;--chakra-sizes-lg:32rem;--chakra-sizes-xl:36rem;--chakra-sizes-2xl:42rem;--chakra-sizes-3xl:48rem;--chakra-sizes-4xl:56rem;--chakra-sizes-5xl:64rem;--chakra-sizes-6xl:72rem;--chakra-sizes-7xl:80rem;--chakra-sizes-8xl:90rem;--chakra-sizes-prose:60ch;--chakra-sizes-container-sm:640px;--chakra-sizes-container-md:768px;--chakra-sizes-container-lg:1024px;--chakra-sizes-container-xl:1280px;--chakra-zIndices-hide:-1;--chakra-zIndices-auto:auto;--chakra-zIndices-base:0;--chakra-zIndices-docked:10;--chakra-zIndices-dropdown:1000;--chakra-zIndices-sticky:1100;--chakra-zIndices-banner:1200;--chakra-zIndices-overlay:1300;--chakra-zIndices-modal:1400;--chakra-zIndices-popover:1500;--chakra-zIndices-skipLink:1600;--chakra-zIndices-toast:1700;--chakra-zIndices-tooltip:1800;--chakra-transition-property-common:background-color,border-color,color,fill,stroke,opacity,box-shadow,transform;--chakra-transition-property-colors:background-color,border-color,color,fill,stroke;--chakra-transition-property-dimensions:width,height;--chakra-transition-property-position:left,right,top,bottom;--chakra-transition-property-background:background-color,background-image,background-position;--chakra-transition-easing-ease-in:cubic-bezier(0.4, 0, 1, 1);--chakra-transition-easing-ease-out:cubic-bezier(0, 0, 0.2, 1);--chakra-transition-easing-ease-in-out:cubic-bezier(0.4, 0, 0.2, 1);--chakra-transition-duration-ultra-fast:50ms;--chakra-transition-duration-faster:100ms;--chakra-transition-duration-fast:150ms;--chakra-transition-duration-normal:200ms;--chakra-transition-duration-slow:300ms;--chakra-transition-duration-slower:400ms;--chakra-transition-duration-ultra-slow:500ms;--chakra-blur-none:0;--chakra-blur-sm:4px;--chakra-blur-base:8px;--chakra-blur-md:12px;--chakra-blur-lg:16px;--chakra-blur-xl:24px;--chakra-blur-2xl:40px;--chakra-blur-3xl:64px;--chakra-breakpoints-base:0em;--chakra-breakpoints-sm:30em;--chakra-breakpoints-md:48em;--chakra-breakpoints-lg:62em;--chakra-breakpoints-xl:80em;--chakra-breakpoints-2xl:96em;}.chakra-ui-light :host:not([data-theme]),.chakra-ui-light :root:not([data-theme]),.chakra-ui-light [data-theme]:not([data-theme]),[data-theme=light] :host:not([data-theme]),[data-theme=light] :root:not([data-theme]),[data-theme=light] [data-theme]:not([data-theme]),:host[data-theme=light],:root[data-theme=light],[data-theme][data-theme=light]{--chakra-colors-chakra-body-text:var(--chakra-colors-gray-800);--chakra-colors-chakra-body-bg:var(--chakra-colors-white);--chakra-colors-chakra-border-color:var(--chakra-colors-gray-200);--chakra-colors-chakra-inverse-text:var(--chakra-colors-white);--chakra-colors-chakra-subtle-bg:var(--chakra-colors-gray-100);--chakra-colors-chakra-subtle-text:var(--chakra-colors-gray-600);--chakra-colors-chakra-placeholder-color:var(--chakra-colors-gray-500);}.chakra-ui-dark :host:not([data-theme]),.chakra-ui-dark :root:not([data-theme]),.chakra-ui-dark [data-theme]:not([data-theme]),[data-theme=dark] :host:not([data-theme]),[data-theme=dark] :root:not([data-theme]),[data-theme=dark] [data-theme]:not([data-theme]),:host[data-theme=dark],:root[data-theme=dark],[data-theme][data-theme=dark]{--chakra-colors-chakra-body-text:var(--chakra-colors-whiteAlpha-900);--chakra-colors-chakra-body-bg:var(--chakra-colors-gray-800);--chakra-colors-chakra-border-color:var(--chakra-colors-whiteAlpha-300);--chakra-colors-chakra-inverse-text:var(--chakra-colors-gray-800);--chakra-colors-chakra-subtle-bg:var(--chakra-colors-gray-700);--chakra-colors-chakra-subtle-text:var(--chakra-colors-gray-400);--chakra-colors-chakra-placeholder-color:var(--chakra-colors-whiteAlpha-400);}</style><style data-emotion="css-global fubdgu">html{line-height:1.5;-webkit-text-size-adjust:100%;font-family:system-ui,sans-serif;-webkit-font-smoothing:antialiased;text-rendering:optimizeLegibility;-moz-osx-font-smoothing:grayscale;touch-action:manipulation;}body{position:relative;min-height:100%;margin:0;font-feature-settings:"kern";}:where(*, *::before, *::after){border-width:0;border-style:solid;box-sizing:border-box;word-wrap:break-word;}main{display:block;}hr{border-top-width:1px;box-sizing:content-box;height:0;overflow:visible;}:where(pre, code, kbd,samp){font-family:SFMono-Regular,Menlo,Monaco,Consolas,monospace;font-size:1em;}a{background-color:transparent;color:inherit;-webkit-text-decoration:inherit;text-decoration:inherit;}abbr[title]{border-bottom:none;-webkit-text-decoration:underline;text-decoration:underline;-webkit-text-decoration:underline dotted;-webkit-text-decoration:underline dotted;text-decoration:underline dotted;}:where(b, strong){font-weight:bold;}small{font-size:80%;}:where(sub,sup){font-size:75%;line-height:0;position:relative;vertical-align:baseline;}sub{bottom:-0.25em;}sup{top:-0.5em;}img{border-style:none;}:where(button, input, optgroup, select, textarea){font-family:inherit;font-size:100%;line-height:1.15;margin:0;}:where(button, input){overflow:visible;}:where(button, select){text-transform:none;}:where(
          button::-moz-focus-inner,
          [type="button"]::-moz-focus-inner,
          [type="reset"]::-moz-focus-inner,
          [type="submit"]::-moz-focus-inner
        ){border-style:none;padding:0;}fieldset{padding:0.35em 0.75em 0.625em;}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal;}progress{vertical-align:baseline;}textarea{overflow:auto;}:where([type="checkbox"], [type="radio"]){box-sizing:border-box;padding:0;}input[type="number"]::-webkit-inner-spin-button,input[type="number"]::-webkit-outer-spin-button{-webkit-appearance:none!important;}input[type="number"]{-moz-appearance:textfield;}input[type="search"]{-webkit-appearance:textfield;outline-offset:-2px;}input[type="search"]::-webkit-search-decoration{-webkit-appearance:none!important;}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit;}details{display:block;}summary{display:-webkit-box;display:-webkit-list-item;display:-ms-list-itembox;display:list-item;}template{display:none;}[hidden]{display:none!important;}:where(
          blockquote,
          dl,
          dd,
          h1,
          h2,
          h3,
          h4,
          h5,
          h6,
          hr,
          figure,
          p,
          pre
        ){margin:0;}button{background:transparent;padding:0;}fieldset{margin:0;padding:0;}:where(ol, ul){margin:0;padding:0;}textarea{resize:vertical;}:where(button, [role="button"]){cursor:pointer;}button::-moz-focus-inner{border:0!important;}table{border-collapse:collapse;}:where(h1, h2, h3, h4, h5, h6){font-size:inherit;font-weight:inherit;}:where(button, input, optgroup, select, textarea){padding:0;line-height:inherit;color:inherit;}:where(img, svg, video, canvas, audio, iframe, embed, object){display:block;}:where(img, video){max-width:100%;height:auto;}[data-js-focus-visible] :focus:not([data-focus-visible-added]):not(
          [data-focus-visible-disabled]
        ){outline:none;box-shadow:none;}select::-ms-expand{display:none;}:root,:host{--chakra-vh:100vh;}@supports (height: -webkit-fill-available){:root,:host{--chakra-vh:-webkit-fill-available;}}@supports (height: -moz-fill-available){:root,:host{--chakra-vh:-moz-fill-available;}}@supports (height: 100dvh){:root,:host{--chakra-vh:100dvh;}}</style><style data-emotion="css-global lbfpqv">body{font-family:var(--chakra-fonts-body);color:var(--chakra-colors-chakra-body-text);background:#202023;transition-property:background-color;transition-duration:var(--chakra-transition-duration-normal);line-height:var(--chakra-lineHeights-base);}*::-webkit-input-placeholder{color:var(--chakra-colors-chakra-placeholder-color);}*::-moz-placeholder{color:var(--chakra-colors-chakra-placeholder-color);}*:-ms-input-placeholder{color:var(--chakra-colors-chakra-placeholder-color);}*::placeholder{color:var(--chakra-colors-chakra-placeholder-color);}*,*::before,::after{border-color:var(--chakra-colors-chakra-border-color);}</style><style data-emotion="css 1lp32oh">.css-1lp32oh{padding-bottom:var(--chakra-space-8);}</style><main class="css-1lp32oh"><style data-emotion="css e1s8q">.css-e1s8q{position:fixed;width:100%;background:#20202380;z-index:2;-webkit-backdrop-filter:blur(10px);backdrop-filter:blur(10px);}</style><nav path="/blog/11_transformers_6" class="css-e1s8q"><style data-emotion="css 1wkbond">.css-1wkbond{width:100%;-webkit-margin-start:auto;margin-inline-start:auto;-webkit-margin-end:auto;margin-inline-end:auto;-webkit-padding-start:var(--chakra-space-4);padding-inline-start:var(--chakra-space-4);-webkit-padding-end:var(--chakra-space-4);padding-inline-end:var(--chakra-space-4);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;padding:var(--chakra-space-2);max-width:var(--chakra-sizes-container-md);}</style><div class="chakra-container css-1wkbond" wrap="wrap" align="center" justify="space-between"><style data-emotion="css qi9cid">.css-qi9cid{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin-right:var(--chakra-space-5);}</style><div class="css-qi9cid"><style data-emotion="css 10zaf98">.css-10zaf98{font-family:var(--chakra-fonts-heading);font-weight:var(--chakra-fontWeights-bold);font-size:var(--chakra-fontSizes-2xl);line-height:1.33;letter-spacing:var(--chakra-letterSpacings-tighter);}@media screen and (min-width: 48em){.css-10zaf98{font-size:var(--chakra-fontSizes-3xl);line-height:1.2;}}</style><h1 class="chakra-heading css-10zaf98"><a href="/"><style data-emotion="css lr1k0q">.css-lr1k0q{font-weight:bold;font-size:18px;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;height:30px;line-height:20px;padding:10px;}.css-lr1k0q >svg{-webkit-transition:500ms ease;transition:500ms ease;}.css-lr1k0q:hover>svg{-webkit-transform:rotate(90deg);-moz-transform:rotate(90deg);-ms-transform:rotate(90deg);transform:rotate(90deg);}</style><span class="css-lr1k0q"><svg width="20" height="20" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><circle cx="10" cy="10" r="10" fill="#333A3F"></circle><path d="M 9 0 L 9 20 M 9 8 L 20 8" stroke="#FFFFFF" stroke-width="0.8"></path><circle cx="5.5" cy="3.9" r=".3" fill="#FFFFFF"></circle><circle cx="17" cy="5" r=".2" fill="#FFFFFF"></circle><circle cx="5" cy="17" r=".2" fill="#FFFFFF"></circle><circle cx="15" cy="15" r=".3" fill="#FFFFFF"></circle></svg><style data-emotion="css ug13ir">.css-ug13ir{margin-left:var(--chakra-space-3);color:var(--chakra-colors-whiteAlpha-900);font-family:M PLUS Rounded 1c;font-weight:var(--chakra-fontWeights-bold);}</style><p class="chakra-text css-ug13ir">Brent Tan</p></span></a></h1></div><style data-emotion="css 4r1ia7">.css-4r1ia7{display:none;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;gap:0.5rem;width:var(--chakra-sizes-full);-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;margin-top:var(--chakra-space-4);}@media screen and (min-width: 48em){.css-4r1ia7{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;width:auto;margin-top:0px;}}</style><div class="chakra-stack css-4r1ia7"><style data-emotion="css fvhngf">.css-fvhngf{transition-property:var(--chakra-transition-property-common);transition-duration:var(--chakra-transition-duration-fast);transition-timing-function:var(--chakra-transition-easing-ease-out);cursor:pointer;-webkit-text-decoration:none;text-decoration:none;outline:2px solid transparent;outline-offset:2px;text-underline-offset:3px;padding:var(--chakra-space-2);color:var(--chakra-colors-whiteAlpha-900);}.css-fvhngf:hover,.css-fvhngf[data-hover]{-webkit-text-decoration:underline;text-decoration:underline;}.css-fvhngf:focus-visible,.css-fvhngf[data-focus-visible]{box-shadow:var(--chakra-shadows-outline);}</style><a class="chakra-link css-fvhngf" href="/writing">Posts</a><a class="chakra-link css-fvhngf" href="/papers">Projects</a><a class="chakra-link css-fvhngf" href="/research">Research</a><style data-emotion="css sy0160">.css-sy0160{transition-property:var(--chakra-transition-property-common);transition-duration:var(--chakra-transition-duration-fast);transition-timing-function:var(--chakra-transition-easing-ease-out);cursor:pointer;-webkit-text-decoration:none;text-decoration:none;outline:2px solid transparent;outline-offset:2px;text-underline-offset:3px;padding:var(--chakra-space-2);color:var(--chakra-colors-whiteAlpha-900);display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding-left:var(--chakra-space-2);}.css-sy0160:hover,.css-sy0160[data-hover]{-webkit-text-decoration:underline;text-decoration:underline;}.css-sy0160:focus-visible,.css-sy0160[data-focus-visible]{box-shadow:var(--chakra-shadows-outline);}</style><a target="_blank" class="chakra-link css-sy0160" style="gap:4px" href="https://github.com/zunyibrt"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M256 32C132.3 32 32 134.9 32 261.7c0 101.5 64.2 187.5 153.2 217.9a17.56 17.56 0 0 0 3.8.4c8.3 0 11.5-6.1 11.5-11.4 0-5.5-.2-19.9-.3-39.1a102.4 102.4 0 0 1-22.6 2.7c-43.1 0-52.9-33.5-52.9-33.5-10.2-26.5-24.9-33.6-24.9-33.6-19.5-13.7-.1-14.1 1.4-14.1h.1c22.5 2 34.3 23.8 34.3 23.8 11.2 19.6 26.2 25.1 39.6 25.1a63 63 0 0 0 25.6-6c2-14.8 7.8-24.9 14.2-30.7-49.7-5.8-102-25.5-102-113.5 0-25.1 8.7-45.6 23-61.6-2.3-5.8-10-29.2 2.2-60.8a18.64 18.64 0 0 1 5-.5c8.1 0 26.4 3.1 56.6 24.1a208.21 208.21 0 0 1 112.2 0c30.2-21 48.5-24.1 56.6-24.1a18.64 18.64 0 0 1 5 .5c12.2 31.6 4.5 55 2.2 60.8 14.3 16.1 23 36.6 23 61.6 0 88.2-52.4 107.6-102.3 113.3 8 7.1 15.2 21.1 15.2 42.5 0 30.7-.3 55.5-.3 63 0 5.4 3.1 11.5 11.4 11.5a19.35 19.35 0 0 0 4-.4C415.9 449.2 480 363.1 480 261.7 480 134.9 379.7 32 256 32z"></path></svg></a></div><style data-emotion="css 1rr4qq7">.css-1rr4qq7{-webkit-flex:1;-ms-flex:1;flex:1;}</style><div align="right" class="css-1rr4qq7"><div style="display:inline-block;opacity:1;will-change:transform,opacity;transform:none"><style data-emotion="css j7xjat">.css-j7xjat{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-appearance:none;-moz-appearance:none;-ms-appearance:none;appearance:none;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:relative;white-space:nowrap;vertical-align:middle;outline:2px solid transparent;outline-offset:2px;line-height:1.2;border-radius:var(--chakra-radii-md);font-weight:var(--chakra-fontWeights-semibold);transition-property:var(--chakra-transition-property-common);transition-duration:var(--chakra-transition-duration-normal);height:var(--chakra-sizes-10);min-width:var(--chakra-sizes-10);font-size:var(--chakra-fontSizes-md);-webkit-padding-start:var(--chakra-space-4);padding-inline-start:var(--chakra-space-4);-webkit-padding-end:var(--chakra-space-4);padding-inline-end:var(--chakra-space-4);background:var(--chakra-colors-orange-200);color:var(--chakra-colors-gray-800);padding:0px;}.css-j7xjat:focus-visible,.css-j7xjat[data-focus-visible]{box-shadow:var(--chakra-shadows-outline);}.css-j7xjat:disabled,.css-j7xjat[disabled],.css-j7xjat[aria-disabled=true],.css-j7xjat[data-disabled]{opacity:0.4;cursor:not-allowed;box-shadow:var(--chakra-shadows-none);}.css-j7xjat:hover,.css-j7xjat[data-hover]{background:var(--chakra-colors-orange-300);}.css-j7xjat:hover:disabled,.css-j7xjat[data-hover]:disabled,.css-j7xjat:hover[disabled],.css-j7xjat[data-hover][disabled],.css-j7xjat:hover[aria-disabled=true],.css-j7xjat[data-hover][aria-disabled=true],.css-j7xjat:hover[data-disabled],.css-j7xjat[data-hover][data-disabled]{background:var(--chakra-colors-orange-200);}.css-j7xjat:active,.css-j7xjat[data-active]{background:var(--chakra-colors-orange-400);}</style><button type="button" class="chakra-button css-j7xjat" aria-label="Toggle theme"><style data-emotion="css onkibi">.css-onkibi{width:1em;height:1em;display:inline-block;line-height:1em;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;color:currentColor;vertical-align:middle;}</style><svg viewBox="0 0 24 24" focusable="false" class="chakra-icon css-onkibi" aria-hidden="true"><g stroke-linejoin="round" stroke-linecap="round" stroke-width="2" fill="none" stroke="currentColor"><circle cx="12" cy="12" r="5"></circle><path d="M12 1v2"></path><path d="M12 21v2"></path><path d="M4.22 4.22l1.42 1.42"></path><path d="M18.36 18.36l1.42 1.42"></path><path d="M1 12h2"></path><path d="M21 12h2"></path><path d="M4.22 19.78l1.42-1.42"></path><path d="M18.36 5.64l1.42-1.42"></path></g></svg></button></div><style data-emotion="css 1q8cyil">.css-1q8cyil{margin-left:var(--chakra-space-2);display:inline-block;}@media screen and (min-width: 48em){.css-1q8cyil{display:none;}}</style><div class="css-1q8cyil"><style data-emotion="css 1wjcgnw">.css-1wjcgnw{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-appearance:none;-moz-appearance:none;-ms-appearance:none;appearance:none;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:relative;white-space:nowrap;vertical-align:middle;outline:2px solid transparent;outline-offset:2px;line-height:1.2;border-radius:var(--chakra-radii-md);font-weight:var(--chakra-fontWeights-semibold);transition-property:var(--chakra-transition-property-common);transition-duration:var(--chakra-transition-duration-normal);height:var(--chakra-sizes-10);min-width:var(--chakra-sizes-10);font-size:var(--chakra-fontSizes-md);-webkit-padding-start:var(--chakra-space-4);padding-inline-start:var(--chakra-space-4);-webkit-padding-end:var(--chakra-space-4);padding-inline-end:var(--chakra-space-4);border:1px solid;border-color:var(--chakra-colors-whiteAlpha-300);color:var(--chakra-colors-whiteAlpha-900);padding:0px;}.css-1wjcgnw:focus-visible,.css-1wjcgnw[data-focus-visible]{box-shadow:var(--chakra-shadows-outline);}.css-1wjcgnw:disabled,.css-1wjcgnw[disabled],.css-1wjcgnw[aria-disabled=true],.css-1wjcgnw[data-disabled]{opacity:0.4;cursor:not-allowed;box-shadow:var(--chakra-shadows-none);}.css-1wjcgnw:hover,.css-1wjcgnw[data-hover]{background:var(--chakra-colors-whiteAlpha-200);}.css-1wjcgnw:hover:disabled,.css-1wjcgnw[data-hover]:disabled,.css-1wjcgnw:hover[disabled],.css-1wjcgnw[data-hover][disabled],.css-1wjcgnw:hover[aria-disabled=true],.css-1wjcgnw[data-hover][aria-disabled=true],.css-1wjcgnw:hover[data-disabled],.css-1wjcgnw[data-hover][data-disabled]{background:initial;}.chakra-button__group[data-attached][data-orientation=horizontal]>.css-1wjcgnw:not(:last-of-type){-webkit-margin-end:-1px;margin-inline-end:-1px;}.chakra-button__group[data-attached][data-orientation=vertical]>.css-1wjcgnw:not(:last-of-type){margin-bottom:-1px;}.css-1wjcgnw:active,.css-1wjcgnw[data-active]{background:var(--chakra-colors-whiteAlpha-300);}</style><button type="button" class="chakra-button chakra-menu__menu-button css-1wjcgnw" aria-label="Options" id="menu-button-navbar-menu" aria-expanded="false" aria-haspopup="menu" aria-controls="menu-list-navbar-menu"><svg viewBox="0 0 24 24" focusable="false" class="chakra-icon css-onkibi" aria-hidden="true"><path fill="currentColor" d="M 3 5 A 1.0001 1.0001 0 1 0 3 7 L 21 7 A 1.0001 1.0001 0 1 0 21 5 L 3 5 z M 3 11 A 1.0001 1.0001 0 1 0 3 13 L 21 13 A 1.0001 1.0001 0 1 0 21 11 L 3 11 z M 3 17 A 1.0001 1.0001 0 1 0 3 19 L 21 19 A 1.0001 1.0001 0 1 0 21 17 L 3 17 z"></path></svg></button><style data-emotion="css r6z5ec">.css-r6z5ec{z-index:1;}</style><div style="visibility:hidden;position:absolute;min-width:max-content;inset:0 auto auto 0" class="css-r6z5ec"><style data-emotion="css 1kfu8nn">.css-1kfu8nn{outline:2px solid transparent;outline-offset:2px;--menu-bg:#fff;--menu-shadow:var(--chakra-shadows-sm);color:inherit;min-width:var(--chakra-sizes-3xs);padding-top:var(--chakra-space-2);padding-bottom:var(--chakra-space-2);z-index:1;border-radius:var(--chakra-radii-md);border-width:1px;background:var(--menu-bg);box-shadow:var(--menu-shadow);}.chakra-ui-dark .css-1kfu8nn:not([data-theme]),[data-theme=dark] .css-1kfu8nn:not([data-theme]),.css-1kfu8nn[data-theme=dark]{--menu-bg:var(--chakra-colors-gray-700);--menu-shadow:var(--chakra-shadows-dark-lg);}</style><div class="chakra-menu__menu-list css-1kfu8nn" tabindex="-1" role="menu" id="menu-list-navbar-menu" aria-orientation="vertical" style="transform-origin:var(--popper-transform-origin);opacity:0;visibility:hidden;transform:scale(0.8)"></div></div></div></div></div></nav><style data-emotion="css 11nbm5x">.css-11nbm5x{width:100%;-webkit-margin-start:auto;margin-inline-start:auto;-webkit-margin-end:auto;margin-inline-end:auto;-webkit-padding-start:var(--chakra-space-4);padding-inline-start:var(--chakra-space-4);-webkit-padding-end:var(--chakra-space-4);padding-inline-end:var(--chakra-space-4);max-width:var(--chakra-sizes-container-md);padding-top:var(--chakra-space-14);}</style><div class="chakra-container css-11nbm5x"><div class="css-0"><style data-emotion="css 130gl9x">.css-130gl9x{text-align:center;margin-bottom:var(--chakra-space-1);}</style><div class="css-130gl9x"><style data-emotion="css 14076z4">.css-14076z4{font-weight:var(--chakra-fontWeights-bold);font-size:var(--chakra-fontSizes-4xl);line-height:1.2;margin-bottom:var(--chakra-space-4);margin-top:var(--chakra-space-5);font-family:Arial;}@media screen and (min-width: 48em){.css-14076z4{font-size:var(--chakra-fontSizes-5xl);line-height:1;}}</style><h1 class="chakra-heading css-14076z4">Building GPT from Scratch - Part 6: Pretraining and Finetuning</h1><style data-emotion="css q9k0mw">.css-q9k0mw{color:var(--chakra-colors-gray-500);}</style><p class="chakra-text css-q9k0mw">Aug 11, 2025</p><style data-emotion="css 14v6z45">.css-14v6z45{opacity:0.6;border:0;border-style:solid;border-bottom-width:1px;width:100%;margin-top:var(--chakra-space-4);margin-bottom:var(--chakra-space-4);border-color:var(--chakra-colors-gray-600);}</style><hr aria-orientation="horizontal" class="chakra-divider css-14v6z45"/></div><style data-emotion="css 1u5ktcn">.css-1u5ktcn{max-width:800px;-webkit-margin-start:auto;margin-inline-start:auto;-webkit-margin-end:auto;margin-inline-end:auto;padding:var(--chakra-space-6);}</style><div class="css-1u5ktcn"><style data-emotion="css 6gleai">.css-6gleai{margin-bottom:var(--chakra-space-4);line-height:1.7;}</style><p class="chakra-text css-6gleai"><em>This is Part 6 of our GPT from scratch series. Having upgraded to modern tokenization in Part 5, we now tackle the data limitation by training on a much larger corpus and exploring pretraining + finetuning.</em></p>
<style data-emotion="css ebdw0u">.css-ebdw0u{font-weight:var(--chakra-fontWeights-bold);font-size:var(--chakra-fontSizes-3xl);line-height:1.33;margin-bottom:var(--chakra-space-4);margin-top:var(--chakra-space-6);font-family:Arial;}@media screen and (min-width: 48em){.css-ebdw0u{font-size:var(--chakra-fontSizes-4xl);line-height:1.2;}}</style><h2 class="chakra-heading css-ebdw0u">Training on a Larger Corpus</h2>
<p class="chakra-text css-6gleai">Since we have a larger model, we now want to train on a larger dataset. I&#x27;m still interested in generating poems, so let&#x27;s use this <style data-emotion="css 1qdxmbw">.css-1qdxmbw{transition-property:var(--chakra-transition-property-common);transition-duration:var(--chakra-transition-duration-fast);transition-timing-function:var(--chakra-transition-easing-ease-out);cursor:pointer;-webkit-text-decoration:none;text-decoration:none;outline:2px solid transparent;outline-offset:2px;color:#ff63c3;text-underline-offset:3px;}.css-1qdxmbw:hover,.css-1qdxmbw[data-hover]{-webkit-text-decoration:underline;text-decoration:underline;}.css-1qdxmbw:focus-visible,.css-1qdxmbw[data-focus-visible]{box-shadow:var(--chakra-shadows-outline);}</style><a target="_blank" rel="noopener" class="chakra-link css-1qdxmbw" href="https://www.kaggle.com/datasets/tgdivy/poetry-foundation-poems">poetry dataset from Kaggle</a> which gives us a CSV file containing a list of poems from <a target="_blank" rel="noopener" class="chakra-link css-1qdxmbw" href="https://www.poetryfoundation.org/">Poetry Foundation</a>.</p>
<p class="chakra-text css-6gleai">We first have to do some data cleaning with pandas to get the newline Unicode characters consistent, and concatenate all the poems into a single text file.</p>
<pre><style data-emotion="css 1ul63h6">.css-1ul63h6{display:inline-block;font-family:var(--chakra-fonts-mono);font-size:var(--chakra-fontSizes-sm);box-shadow:var(--badge-shadow);--badge-bg:var(--chakra-colors-gray-100);--badge-color:var(--chakra-colors-gray-800);-webkit-padding-start:var(--chakra-space-2);padding-inline-start:var(--chakra-space-2);-webkit-padding-end:var(--chakra-space-2);padding-inline-end:var(--chakra-space-2);padding-top:0.95px;padding-bottom:0.95px;background:var(--chakra-colors-gray-900);color:var(--chakra-colors-white);border-radius:var(--chakra-radii-md);}.chakra-ui-dark .css-1ul63h6:not([data-theme]),[data-theme=dark] .css-1ul63h6:not([data-theme]),.css-1ul63h6[data-theme=dark]{--badge-bg:rgba(226, 232, 240, 0.16);--badge-color:var(--chakra-colors-gray-200);}</style><code class="chakra-code css-1ul63h6">Line terminators found in the poems:
----------------------------------------
Mac Classic (\r only): 417494 occurrences
Double CR + LF (\r\r\n): 379146 occurrences
Windows (\r\n): 379146 occurrences
Reversed (\n\r): 19556 occurrences
Double CR (\r\r): 10527 occurrences
Line Separator (U+2028): 419 occurrences
Paragraph Separator (U+2029): 1 occurrences
----------------------------------------

Successfully concatenated 13854 poems into &#x27;all_poems_cleaned.txt&#x27;

Sample cleaning (poem at index 101):
Original: &#x27;\r\r\nThe sound of a guitar drifts through the air.\r\r\nCupped in my hand, a snowflake quivers lightly.\r\r&#x27;...
Cleaned: &#x27;The sound of a guitar drifts through the air.\nCupped in my hand, a snowflake quivers lightly.\nThick &#x27;...
</code></pre>
<p class="chakra-text css-6gleai">This file is around 20MB and 400,000 lines long, which is 20 times the size and 10 times the number of lines of the Shakespeare dataset.</p>
<h2 class="chakra-heading css-ebdw0u">Training Results on Poetry Dataset</h2>
<pre><code class="chakra-code css-1ul63h6">step 0: train loss 10.8247, val loss 10.8255
step 100: train loss 6.2405, val loss 6.5146
step 200: train loss 5.7141, val loss 6.2657
step 300: train loss 5.5298, val loss 6.1561
step 400: train loss 5.4678, val loss 5.8279
step 500: train loss 5.5526, val loss 5.7174
step 600: train loss 5.2497, val loss 5.6578
step 700: train loss 5.1549, val loss 5.6028
step 800: train loss 5.0009, val loss 5.7194
step 900: train loss 5.2021, val loss 5.5778
step 1000: train loss 4.8988, val loss 5.5454
step 1100: train loss 4.9935, val loss 5.4814
step 1200: train loss 4.9520, val loss 5.3551
step 1300: train loss 5.0129, val loss 5.3685
step 1400: train loss 4.9534, val loss 5.3807
step 1500: train loss 4.7947, val loss 5.3912
step 1600: train loss 5.0557, val loss 5.2993
step 1700: train loss 4.8419, val loss 5.2611
step 1800: train loss 4.7657, val loss 5.0324
step 1900: train loss 4.4551, val loss 5.0815
step 2000: train loss 4.6674, val loss 5.1306
step 2100: train loss 4.6318, val loss 5.0484
step 2200: train loss 4.6357, val loss 5.2188
step 2300: train loss 4.5006, val loss 4.9910
step 2400: train loss 4.3960, val loss 5.0353
step 2500: train loss 4.4227, val loss 5.0051
step 2600: train loss 4.4193, val loss 4.9974
step 2700: train loss 4.4097, val loss 4.9683
step 2800: train loss 4.2323, val loss 4.9965
step 2900: train loss 4.3671, val loss 4.8900
step 3000: train loss 4.3548, val loss 4.8972
step 3100: train loss 4.3923, val loss 4.7957
step 3200: train loss 4.4397, val loss 4.7694
step 3300: train loss 4.3573, val loss 4.9981
step 3400: train loss 4.3772, val loss 4.8391
step 3500: train loss 4.3908, val loss 4.8069
step 3600: train loss 4.2172, val loss 4.7400
step 3700: train loss 4.1613, val loss 4.8643
step 3800: train loss 4.2559, val loss 4.9014
step 3900: train loss 4.0760, val loss 4.7784
step 4000: train loss 3.9681, val loss 4.7814
step 4100: train loss 4.0662, val loss 4.8351
step 4200: train loss 4.1156, val loss 4.9005
step 4300: train loss 4.1036, val loss 4.7409
step 4400: train loss 4.0790, val loss 4.6941
step 4500: train loss 4.1168, val loss 4.8207
step 4600: train loss 3.8932, val loss 4.7466
step 4700: train loss 4.0971, val loss 4.9108
step 4800: train loss 4.0825, val loss 4.8164
step 4900: train loss 4.0249, val loss 4.7728
step 4999: train loss 4.0157, val loss 4.7919
</code></pre>
<p class="chakra-text css-6gleai">The model generates much more diverse and poetic text:</p>
<pre><code class="chakra-code css-1ul63h6">! but ...  
beautise on a head, everything&#x27;s
served, seemed—
Lewash on the back of the garbled pllesh,
are not to be vigilant
by food, tears, eyes burnt,
dust and screaming. Just say —I&#x27;ve brought
Grandter aesthetics—
maybe God like John Fanny or that.7.
Everything&#x27;s that alonghed in.
Butoried to me
when he yelled.

Just urboilherer appeared. Then he were falling, sits crying and prayed to his brother, being missing. They started on time they went up, though
God said his father had to stop a good reporters
stand, locked, hooves, feet up tighter, &quot;Is smooth?&quot;
The Morning
Season explores the world of the walls
Gazels through the light. Later each day,
A reasonably thing is beauties
At evening a while Frains unself from a walk.Zusted in light old
The way used to the land. On the snow?
There said, &quot;Not offensive.&quot; &quot;but that&#x27;s the trietry, &quot;Nor does
say, but it&quot; with footage,
 Maoaching the crowd.&quot;You like the power actual
or on in their apartmentrelices, and the vinyl themselves lie together by that the Jewish sound.&quot; So, in one hand,
you could folding it backdroaches and wall you made
had keep what&#x27;﻿s done.&quot; and I stared, picking a grump offpour, and stared on the smoke, tapped to a wheel and the twos winkboat.
The house was a cigar on my stopes of dilelict and
those threatened hunger from how to be at moving steadily, could never believe
as white but a man with pens would not take  to. I could remember that night.
The moon was thick, the wind rivening the waves of the sea, the swift dark whiteerly recedes
from are it and its silkency of    paths comprising sleep, a rail of o&#x27;clock. Outspread it somewhere,
and if it ever repeated; soon, just angularling forward, the magager and schimology.The rifle wasn&#x27;t wobbling paths and blinked,
</code></pre>
<h2 class="chakra-heading css-ebdw0u">Further Training Attempts</h2>
<p class="chakra-text css-6gleai">To try and further improve, we try training longer and with a learning rate that is ten times smaller. However, both training and validation seem to have saturated. We also try a cosine learning rate with multiple restarts, but the results are not very good:</p>
<pre><style data-emotion="css 1t1ewm6">.css-1t1ewm6{font-family:var(--chakra-fonts-mono);font-size:var(--chakra-fontSizes-sm);-webkit-padding-start:0.2em;padding-inline-start:0.2em;-webkit-padding-end:0.2em;padding-inline-end:0.2em;box-shadow:var(--badge-shadow);--badge-bg:var(--chakra-colors-gray-100);--badge-color:var(--chakra-colors-gray-800);display:block;padding:var(--chakra-space-4);background:var(--chakra-colors-gray-900);color:var(--chakra-colors-white);border-radius:var(--chakra-radii-md);overflow:auto;margin-bottom:var(--chakra-space-4);}.chakra-ui-dark .css-1t1ewm6:not([data-theme]),[data-theme=dark] .css-1t1ewm6:not([data-theme]),.css-1t1ewm6[data-theme=dark]{--badge-bg:rgba(226, 232, 240, 0.16);--badge-color:var(--chakra-colors-gray-200);}</style><code class="chakra-code css-1t1ewm6">step_lr = config.learning_rate*np.cos(<span class="hljs-number">0.5</span>*np.pi*<span class="hljs-built_in">iter</span>/(config.max_iters-<span class="hljs-number">1</span>))
<span class="hljs-keyword">for</span> group <span class="hljs-keyword">in</span> optimizer.param_groups:
  group[<span class="hljs-string">&#x27;lr&#x27;</span>] = step_lr
</code></pre>
<pre><code class="chakra-code css-1ul63h6">step 0: train loss 10.8202, val loss 10.8287
...
step 3000: train loss 4.5538, val loss 5.0448
...
step 1000: train loss 4.5272, val loss 4.9344
...
step 999: train loss 4.2557, val loss 4.8072
...
step 999: train loss 4.0713, val loss 4.7289
...
step 999: train loss 4.1581, val loss 4.8483
</code></pre>
<p class="chakra-text css-6gleai">Next, we try reshuffling the training and validation split of the input data by using the first 10% for validation instead. We find that training loss is now higher, another sign we were overfitting. After further training, we end up with training loss and validation loss being about 4. The final result is decent:</p>
<pre><code class="chakra-code css-1ul63h6">Summer dazed
with its theatrical designs, tubes, guts.
I clump the bripscrewed black.
I share the precise whatever
not actually needed.
I say when it grazed the time,
things myself between them
and there&#x27;s little wings forth
English stains, the slick cold force.
Running the basement that moved
never. I wonder whether it meant
that this sad adventure within and
unlemishes the dead.
I was writing that Old Friend was
always working on I have
seen many plans seeing unsatisfied,
she was always ashamed
of this region.
I think of the Second Coming
asleep clear as I thought
waswitch recognized yet because of himself
were not afraid of me
but this sequence after the war
that had been doing to me
don&#x27;t hurt me I meant so many years ago.
I wasn&#x27;t my brother.
</code></pre>
<h2 class="chakra-heading css-ebdw0u">Finetuning on Shakespeare</h2>
<p class="chakra-text css-6gleai">Lastly, we try finetuning on the tiny Shakespeare dataset we started with. We have essentially pretrained our larger model on the larger poetry dataset and now use a much lower learning rate (3e-6) and 10,000 training iterations to refine on the smaller tiny Shakespeare dataset.</p>
<pre><code class="chakra-code css-1ul63h6">step 10000: train loss 3.1057, val loss 4.1152
</code></pre>
<p class="chakra-text css-6gleai">This is much better than when we just tried to train our larger model with the GPT-2 tokenizer on the Shakespeare data alone. This is the advantage of pretraining! Here are the results:</p>
<pre><code class="chakra-code css-1ul63h6">Is he contented himself with his exercise,
Even he that fall&#x27;d upon his tent with him
The ground o&#x27;er his bed, his dole from the north,
And cries &#x27;He well.&#x27;
And Tranio, which consummate honour, in turn
Proclaims him on his way; and he cried,
Lay him that comments mortals play out.

LADY CAPULET:
My lords, I will not hear my traitor.

DUKE VINCENTIO:
Wrut, away! thou shalt never weep;
And yet I have received thy royal presence,
Having done the corse. But thou&#x27;ll hear be
My father&#x27;s son, blessing in the cruel gown,
though mine own buried heir
Our father&#x27;s poor son, my poor daughter, my child,
Where I am resign&#x27;d me; and I will be king,
And pain&#x27;d the house of this churchyard call.
Thy father, and I seek thee here;
So, newly wench&#x27;d with that great aspect,
And thy servile&#x27; mortal presence made me,
And thou wouldst board thy mortal bones
In readiness, he may hear it bear.
Ah, art thou law to be made my nurse.

LADY CAPULET:
Ay, I&#x27;ll win thee would not woe awhile.

DUKE OF YORK:
O gentle Plantagenet queen,

ISABELLA:
Ah, my lord, thou art safe and younger!

DUKE OF YORK:
Farewell with us, bleated those that have said,
That we should plague thee for many days.

KING RICHARD II:
Give me my father to your brother&#x27;s house,
Or else send him by your fortunes to the street.
What art thou slain?

GLOUCESTER:
Harry of York, I tell thee that kill thy life:
And thou, contracted hither to my farm,
Thou art so happy to be repelling&#x27;d at thy mind!
As on a day that pageant thou sufficiency,
Now let thy father speak before thy function.

KING RICHARD II:
O coward to this day; there comes Hereford with thee!
</code></pre>
<p class="chakra-text css-6gleai">Wow! While it&#x27;s still not perfectly coherent, it seems much better than our output from the character-level tokenizer. Some characters even have multiple lines!</p>
<h2 class="chakra-heading css-ebdw0u">Key Insights</h2>
<p class="chakra-text css-6gleai">This part demonstrates several important concepts in modern language model training:</p>
<style data-emotion="css 11bj9n">.css-11bj9n{list-style-type:decimal;-webkit-margin-start:1em;margin-inline-start:1em;margin-bottom:var(--chakra-space-4);}.css-11bj9n>*:not(style)~*:not(style){margin-top:var(--chakra-space-2);}</style><ol role="list" class="css-11bj9n"><li class="css-0">
<p class="chakra-text css-6gleai"><strong>Dataset Scale Matters</strong>: The larger poetry dataset (20x bigger) significantly improved text quality and diversity.</p>
</li><li class="css-0">
<p class="chakra-text css-6gleai"><strong>Data Cleaning is Critical</strong>: Proper handling of line terminators and text formatting is essential for good training data.</p>
</li><li class="css-0">
<p class="chakra-text css-6gleai"><strong>Pretraining + Finetuning Works</strong>: The two-stage approach of pretraining on a large diverse corpus, then finetuning on a specific domain, produces better results than training on the target domain alone.</p>
</li><li class="css-0">
<p class="chakra-text css-6gleai"><strong>Overfitting Remains a Challenge</strong>: Even with more data, the model still shows signs of overfitting, indicating we need even more data or better regularization.</p>
</li><li class="css-0">
<p class="chakra-text css-6gleai"><strong>Modern Tokenization Benefits</strong>: Subword tokens produce more natural-looking text even when the model isn&#x27;t perfectly trained.</p>
</li></ol>
<p class="chakra-text css-6gleai">The progression from character-level Shakespeare generation to subword-level poetry and then Shakespeare finetuning shows the power of scaling both model size and training data in the right sequence.</p></div></div><style data-emotion="css 17cqjj4">.css-17cqjj4{opacity:0.4;font-size:var(--chakra-fontSizes-sm);}</style><div align="center" class="css-17cqjj4">Build based on <a href="https://www.craftz.dog/" target="_blank">Takuya Matsuyama</a>.</div></div></main><span></span><span id="__chakra_env" hidden=""></span></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"slug":"11_transformers_6","content":"*This is Part 6 of our GPT from scratch series. Having upgraded to modern tokenization in Part 5, we now tackle the data limitation by training on a much larger corpus and exploring pretraining + finetuning.*\n\n## Training on a Larger Corpus\n\nSince we have a larger model, we now want to train on a larger dataset. I'm still interested in generating poems, so let's use this [poetry dataset from Kaggle](https://www.kaggle.com/datasets/tgdivy/poetry-foundation-poems) which gives us a CSV file containing a list of poems from [Poetry Foundation](https://www.poetryfoundation.org/). \n\nWe first have to do some data cleaning with pandas to get the newline Unicode characters consistent, and concatenate all the poems into a single text file.\n\n```\nLine terminators found in the poems:\n----------------------------------------\nMac Classic (\\r only): 417494 occurrences\nDouble CR + LF (\\r\\r\\n): 379146 occurrences\nWindows (\\r\\n): 379146 occurrences\nReversed (\\n\\r): 19556 occurrences\nDouble CR (\\r\\r): 10527 occurrences\nLine Separator (U+2028): 419 occurrences\nParagraph Separator (U+2029): 1 occurrences\n----------------------------------------\n\nSuccessfully concatenated 13854 poems into 'all_poems_cleaned.txt'\n\nSample cleaning (poem at index 101):\nOriginal: '\\r\\r\\nThe sound of a guitar drifts through the air.\\r\\r\\nCupped in my hand, a snowflake quivers lightly.\\r\\r'...\nCleaned: 'The sound of a guitar drifts through the air.\\nCupped in my hand, a snowflake quivers lightly.\\nThick '...\n```\n\nThis file is around 20MB and 400,000 lines long, which is 20 times the size and 10 times the number of lines of the Shakespeare dataset.\n\n## Training Results on Poetry Dataset\n\n```\nstep 0: train loss 10.8247, val loss 10.8255\nstep 100: train loss 6.2405, val loss 6.5146\nstep 200: train loss 5.7141, val loss 6.2657\nstep 300: train loss 5.5298, val loss 6.1561\nstep 400: train loss 5.4678, val loss 5.8279\nstep 500: train loss 5.5526, val loss 5.7174\nstep 600: train loss 5.2497, val loss 5.6578\nstep 700: train loss 5.1549, val loss 5.6028\nstep 800: train loss 5.0009, val loss 5.7194\nstep 900: train loss 5.2021, val loss 5.5778\nstep 1000: train loss 4.8988, val loss 5.5454\nstep 1100: train loss 4.9935, val loss 5.4814\nstep 1200: train loss 4.9520, val loss 5.3551\nstep 1300: train loss 5.0129, val loss 5.3685\nstep 1400: train loss 4.9534, val loss 5.3807\nstep 1500: train loss 4.7947, val loss 5.3912\nstep 1600: train loss 5.0557, val loss 5.2993\nstep 1700: train loss 4.8419, val loss 5.2611\nstep 1800: train loss 4.7657, val loss 5.0324\nstep 1900: train loss 4.4551, val loss 5.0815\nstep 2000: train loss 4.6674, val loss 5.1306\nstep 2100: train loss 4.6318, val loss 5.0484\nstep 2200: train loss 4.6357, val loss 5.2188\nstep 2300: train loss 4.5006, val loss 4.9910\nstep 2400: train loss 4.3960, val loss 5.0353\nstep 2500: train loss 4.4227, val loss 5.0051\nstep 2600: train loss 4.4193, val loss 4.9974\nstep 2700: train loss 4.4097, val loss 4.9683\nstep 2800: train loss 4.2323, val loss 4.9965\nstep 2900: train loss 4.3671, val loss 4.8900\nstep 3000: train loss 4.3548, val loss 4.8972\nstep 3100: train loss 4.3923, val loss 4.7957\nstep 3200: train loss 4.4397, val loss 4.7694\nstep 3300: train loss 4.3573, val loss 4.9981\nstep 3400: train loss 4.3772, val loss 4.8391\nstep 3500: train loss 4.3908, val loss 4.8069\nstep 3600: train loss 4.2172, val loss 4.7400\nstep 3700: train loss 4.1613, val loss 4.8643\nstep 3800: train loss 4.2559, val loss 4.9014\nstep 3900: train loss 4.0760, val loss 4.7784\nstep 4000: train loss 3.9681, val loss 4.7814\nstep 4100: train loss 4.0662, val loss 4.8351\nstep 4200: train loss 4.1156, val loss 4.9005\nstep 4300: train loss 4.1036, val loss 4.7409\nstep 4400: train loss 4.0790, val loss 4.6941\nstep 4500: train loss 4.1168, val loss 4.8207\nstep 4600: train loss 3.8932, val loss 4.7466\nstep 4700: train loss 4.0971, val loss 4.9108\nstep 4800: train loss 4.0825, val loss 4.8164\nstep 4900: train loss 4.0249, val loss 4.7728\nstep 4999: train loss 4.0157, val loss 4.7919\n```\n\nThe model generates much more diverse and poetic text:\n\n```\n! but ...  \nbeautise on a head, everything's\nserved, seemed—\nLewash on the back of the garbled pllesh,\nare not to be vigilant\nby food, tears, eyes burnt,\ndust and screaming. Just say —I've brought\nGrandter aesthetics—\nmaybe God like John Fanny or that.7.\nEverything's that alonghed in.\nButoried to me\nwhen he yelled.\n\nJust urboilherer appeared. Then he were falling, sits crying and prayed to his brother, being missing. They started on time they went up, though\nGod said his father had to stop a good reporters\nstand, locked, hooves, feet up tighter, \"Is smooth?\"\nThe Morning\nSeason explores the world of the walls\nGazels through the light. Later each day,\nA reasonably thing is beauties\nAt evening a while Frains unself from a walk.Zusted in light old\nThe way used to the land. On the snow?\nThere said, \"Not offensive.\" \"but that's the trietry, \"Nor does\nsay, but it\" with footage,\n Maoaching the crowd.\"You like the power actual\nor on in their apartmentrelices, and the vinyl themselves lie together by that the Jewish sound.\" So, in one hand,\nyou could folding it backdroaches and wall you made\nhad keep what'﻿s done.\" and I stared, picking a grump offpour, and stared on the smoke, tapped to a wheel and the twos winkboat.\nThe house was a cigar on my stopes of dilelict and\nthose threatened hunger from how to be at moving steadily, could never believe\nas white but a man with pens would not take  to. I could remember that night.\nThe moon was thick, the wind rivening the waves of the sea, the swift dark whiteerly recedes\nfrom are it and its silkency of    paths comprising sleep, a rail of o'clock. Outspread it somewhere,\nand if it ever repeated; soon, just angularling forward, the magager and schimology.The rifle wasn't wobbling paths and blinked,\n```\n\n## Further Training Attempts\n\nTo try and further improve, we try training longer and with a learning rate that is ten times smaller. However, both training and validation seem to have saturated. We also try a cosine learning rate with multiple restarts, but the results are not very good:\n\n```python\nstep_lr = config.learning_rate*np.cos(0.5*np.pi*iter/(config.max_iters-1))\nfor group in optimizer.param_groups:\n  group['lr'] = step_lr\n```\n\n```\nstep 0: train loss 10.8202, val loss 10.8287\n...\nstep 3000: train loss 4.5538, val loss 5.0448\n...\nstep 1000: train loss 4.5272, val loss 4.9344\n...\nstep 999: train loss 4.2557, val loss 4.8072\n...\nstep 999: train loss 4.0713, val loss 4.7289\n...\nstep 999: train loss 4.1581, val loss 4.8483\n```\n\nNext, we try reshuffling the training and validation split of the input data by using the first 10% for validation instead. We find that training loss is now higher, another sign we were overfitting. After further training, we end up with training loss and validation loss being about 4. The final result is decent:\n\n```\nSummer dazed\nwith its theatrical designs, tubes, guts.\nI clump the bripscrewed black.\nI share the precise whatever\nnot actually needed.\nI say when it grazed the time,\nthings myself between them\nand there's little wings forth\nEnglish stains, the slick cold force.\nRunning the basement that moved\nnever. I wonder whether it meant\nthat this sad adventure within and\nunlemishes the dead.\nI was writing that Old Friend was\nalways working on I have\nseen many plans seeing unsatisfied,\nshe was always ashamed\nof this region.\nI think of the Second Coming\nasleep clear as I thought\nwaswitch recognized yet because of himself\nwere not afraid of me\nbut this sequence after the war\nthat had been doing to me\ndon't hurt me I meant so many years ago.\nI wasn't my brother.\n```\n\n## Finetuning on Shakespeare\n\nLastly, we try finetuning on the tiny Shakespeare dataset we started with. We have essentially pretrained our larger model on the larger poetry dataset and now use a much lower learning rate (3e-6) and 10,000 training iterations to refine on the smaller tiny Shakespeare dataset.\n\n```\nstep 10000: train loss 3.1057, val loss 4.1152\n```\n\nThis is much better than when we just tried to train our larger model with the GPT-2 tokenizer on the Shakespeare data alone. This is the advantage of pretraining! Here are the results:\n\n```\nIs he contented himself with his exercise,\nEven he that fall'd upon his tent with him\nThe ground o'er his bed, his dole from the north,\nAnd cries 'He well.'\nAnd Tranio, which consummate honour, in turn\nProclaims him on his way; and he cried,\nLay him that comments mortals play out.\n\nLADY CAPULET:\nMy lords, I will not hear my traitor.\n\nDUKE VINCENTIO:\nWrut, away! thou shalt never weep;\nAnd yet I have received thy royal presence,\nHaving done the corse. But thou'll hear be\nMy father's son, blessing in the cruel gown,\nthough mine own buried heir\nOur father's poor son, my poor daughter, my child,\nWhere I am resign'd me; and I will be king,\nAnd pain'd the house of this churchyard call.\nThy father, and I seek thee here;\nSo, newly wench'd with that great aspect,\nAnd thy servile' mortal presence made me,\nAnd thou wouldst board thy mortal bones\nIn readiness, he may hear it bear.\nAh, art thou law to be made my nurse.\n\nLADY CAPULET:\nAy, I'll win thee would not woe awhile.\n\nDUKE OF YORK:\nO gentle Plantagenet queen,\n\nISABELLA:\nAh, my lord, thou art safe and younger!\n\nDUKE OF YORK:\nFarewell with us, bleated those that have said,\nThat we should plague thee for many days.\n\nKING RICHARD II:\nGive me my father to your brother's house,\nOr else send him by your fortunes to the street.\nWhat art thou slain?\n\nGLOUCESTER:\nHarry of York, I tell thee that kill thy life:\nAnd thou, contracted hither to my farm,\nThou art so happy to be repelling'd at thy mind!\nAs on a day that pageant thou sufficiency,\nNow let thy father speak before thy function.\n\nKING RICHARD II:\nO coward to this day; there comes Hereford with thee!\n```\n\nWow! While it's still not perfectly coherent, it seems much better than our output from the character-level tokenizer. Some characters even have multiple lines!\n\n## Key Insights\n\nThis part demonstrates several important concepts in modern language model training:\n\n1. **Dataset Scale Matters**: The larger poetry dataset (20x bigger) significantly improved text quality and diversity.\n\n2. **Data Cleaning is Critical**: Proper handling of line terminators and text formatting is essential for good training data.\n\n3. **Pretraining + Finetuning Works**: The two-stage approach of pretraining on a large diverse corpus, then finetuning on a specific domain, produces better results than training on the target domain alone.\n\n4. **Overfitting Remains a Challenge**: Even with more data, the model still shows signs of overfitting, indicating we need even more data or better regularization.\n\n5. **Modern Tokenization Benefits**: Subword tokens produce more natural-looking text even when the model isn't perfectly trained.\n\nThe progression from character-level Shakespeare generation to subword-level poetry and then Shakespeare finetuning shows the power of scaling both model size and training data in the right sequence.","title":"Building GPT from Scratch - Part 6: Pretraining and Finetuning","date":"2025-08-11","excerpt":"","tags":["transformers","tutorial"]}},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"11_transformers_6"},"buildId":"FUrf4hjRe_AMnPlFUzSZF","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>